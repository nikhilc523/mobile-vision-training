# Fall Detection Project - Week 4 Report (FINAL)

**Student:** Nikhil Chowdary  
**Project:** Real-Time Fall Detection Using Pose Estimation and LSTM  
**Week:** 4 of 4 (November 7-13, 2025)  
**Report Date:** November 15, 2025

---

## ğŸ“‹ Executive Summary

Week 4 focused on **completing feature engineering, training final model, and comprehensive evaluation**. [TO BE FILLED AFTER COMPLETION]

### Key Metrics
- **Features Implemented:** [X]/10
- **Windows Generated:** [X] (from 964 videos)
- **Final Model Trained:** [âœ…/â³]
- **Test F1 Score:** [X.XXX]
- **Test Recall:** [X.XXX]
- **Test Precision:** [X.XXX]
- **Model Size:** [X] KB
- **Time Spent:** [X] hours

---

## âœ… Accomplishments

### 1. Feature Engineering on Full Dataset (GitHub Issue #7) - [STATUS]

**Objective:** Re-run feature engineering on all 964 videos to generate ~10,000+ windows.

**Tasks Completed:**
- [ ] Updated `ml/features/feature_engineering.py` to process all datasets
- [ ] Added CLI argument `--dataset all`
- [ ] Ran feature engineering on full 964 videos
- [ ] Verified window count: [X] windows generated
- [ ] Checked class balance: [X]% fall / [X]% non-fall
- [ ] Updated documentation

**Results:**
```
Input: 964 videos (63 URFD + 190 Le2i + 711 UCF101)
â”œâ”€â”€ Total Frames: 197,411
â”œâ”€â”€ Potential Windows: [X]
â””â”€â”€ After Quality Filtering: [X] windows ([X]% dropped)

Output: data/processed/full_windows.npz
â”œâ”€â”€ X shape: ([X], 60, 6)  # [X] windows, 60 frames, 6 features
â”œâ”€â”€ y shape: ([X],)        # [X] labels
â””â”€â”€ Class Balance:
    â”œâ”€â”€ Fall (1): [X] windows ([X]%)
    â””â”€â”€ Non-Fall (0): [X] windows ([X]%)

Processing Time: [X] minutes
```

**Time Spent:** [X] hours

---

### 2. Add 4 Additional Features (GitHub Issue #8) - [STATUS]

**Objective:** Implement 4 more features to reach 10 total (as per proposal).

**Tasks Completed:**
- [ ] Implemented bounding box area calculation
- [ ] Implemented head velocity calculation
- [ ] Implemented limb angles calculation
- [ ] Implemented pose confidence calculation
- [ ] Updated `ml/features/feature_engineering.py`
- [ ] Tested on sample data
- [ ] Verified feature ranges and distributions
- [ ] Created visualizations
- [ ] Re-ran on full dataset with 10 features

**New Features:**
7. **Bounding Box Area** - [DESCRIPTION]
8. **Head Velocity** - [DESCRIPTION]
9. **Limb Angles** - [DESCRIPTION]
10. **Pose Confidence** - [DESCRIPTION]

**Results:**
```
Output: data/processed/full_windows_10feat.npz
â”œâ”€â”€ X shape: ([X], 60, 10)  # [X] windows, 60 frames, 10 features
â”œâ”€â”€ y shape: ([X],)         # [X] labels

Feature Statistics:
â”œâ”€â”€ Torso Angle: mean=[X]Â°, std=[X]Â°
â”œâ”€â”€ Hip Height: mean=[X], std=[X]
â”œâ”€â”€ Vertical Velocity: mean=[X], std=[X]
â”œâ”€â”€ Motion Magnitude: mean=[X], std=[X]
â”œâ”€â”€ Shoulder Symmetry: mean=[X], std=[X]
â”œâ”€â”€ Knee Angle: mean=[X]Â°, std=[X]Â°
â”œâ”€â”€ Bounding Box Area: mean=[X], std=[X]
â”œâ”€â”€ Head Velocity: mean=[X], std=[X]
â”œâ”€â”€ Limb Angles: mean=[X]Â°, std=[X]Â°
â””â”€â”€ Pose Confidence: mean=[X], std=[X]
```

**Time Spent:** [X] hours

---

### 3. Implement Focal Loss (GitHub Issue #10) - [STATUS]

**Objective:** Implement focal loss to handle class imbalance.

**Tasks Completed:**
- [ ] Installed TensorFlow Addons
- [ ] Imported `SigmoidFocalCrossEntropy`
- [ ] Updated `ml/training/lstm_train.py`
- [ ] Added CLI arguments `--focal-loss`, `--focal-alpha`, `--focal-gamma`
- [ ] Tested on proof-of-concept dataset
- [ ] Compared performance with standard BCE
- [ ] Documented results

**Configuration:**
```python
focal_loss = SigmoidFocalCrossEntropy(
    alpha=[X],  # Weight for positive class
    gamma=[X],  # Focusing parameter
)
```

**Performance Comparison:**
```
Standard BCE:
â”œâ”€â”€ F1: [X.XXX]
â”œâ”€â”€ Recall: [X.XXX]
â””â”€â”€ Precision: [X.XXX]

Focal Loss:
â”œâ”€â”€ F1: [X.XXX] ([+/-X.XXX])
â”œâ”€â”€ Recall: [X.XXX] ([+/-X.XXX])
â””â”€â”€ Precision: [X.XXX] ([+/-X.XXX])
```

**Time Spent:** [X] hours

---

### 4. Implement Subject-Wise Splitting (GitHub Issue #11) - [STATUS]

**Objective:** Implement subject-wise data splitting to prevent data leakage.

**Tasks Completed:**
- [ ] Extracted subject/video identifiers from filenames
- [ ] Grouped windows by subject/video
- [ ] Implemented subject-wise train/val/test split (70/15/15)
- [ ] Verified no subject overlap between splits
- [ ] Updated `ml/features/feature_engineering.py` to save subject IDs
- [ ] Updated `ml/training/lstm_train.py` to use subject-wise splitting
- [ ] Added CLI argument `--split-by subject`
- [ ] Created verification script
- [ ] Documented approach

**Split Statistics:**
```
Total Subjects: [X]
â”œâ”€â”€ Train: [X] subjects ([X]%)
â”œâ”€â”€ Val: [X] subjects ([X]%)
â””â”€â”€ Test: [X] subjects ([X]%)

Total Windows: [X]
â”œâ”€â”€ Train: [X] windows ([X]%)
â”œâ”€â”€ Val: [X] windows ([X]%)
â””â”€â”€ Test: [X] windows ([X]%)

Verification:
â”œâ”€â”€ Subject Overlap: 0 âœ…
â”œâ”€â”€ Class Balance Maintained: [âœ…/âŒ]
â””â”€â”€ Split Ratios: [X]/[X]/[X]
```

**Time Spent:** [X] hours

---

### 5. Train Final Model on Full Dataset (GitHub Issue #12) - [STATUS]

**Objective:** Train final LSTM model on full dataset with all improvements.

**Tasks Completed:**
- [ ] Loaded full dataset ([X] windows, 10 features)
- [ ] Applied subject-wise splitting (70/15/15)
- [ ] Configured model with focal loss
- [ ] Enabled data augmentation
- [ ] Trained for 100 epochs with early stopping
- [ ] Monitored training metrics
- [ ] Saved best model checkpoint
- [ ] Generated training visualizations
- [ ] Calculated test metrics
- [ ] Compared with baseline (17-sample model)

**Training Configuration:**
```bash
python -m ml.training.lstm_train \
    --data data/processed/full_windows_10feat.npz \
    --epochs 100 \
    --batch 32 \
    --lr 1e-3 \
    --focal-loss \
    --focal-alpha 0.25 \
    --focal-gamma 2.0 \
    --split-by subject \
    --augment \
    --save-best \
    --output ml/training/checkpoints/lstm_final.h5
```

**Training Results:**
```
Dataset Split:
â”œâ”€â”€ Train: [X] samples ([X]%)
â”œâ”€â”€ Val: [X] samples ([X]%)
â””â”€â”€ Test: [X] samples ([X]%)

Model Architecture:
â”œâ”€â”€ Parameters: 20,289
â”œâ”€â”€ Trainable: 20,289
â”œâ”€â”€ Model Size: [X] KB

Training:
â”œâ”€â”€ Epochs: [X] (early stopping at epoch [X])
â”œâ”€â”€ Best Val Loss: [X.XXX]
â”œâ”€â”€ Best Val F1: [X.XXX]
â”œâ”€â”€ Training Time: [X] minutes

Test Metrics:
â”œâ”€â”€ Precision: [X.XXX]
â”œâ”€â”€ Recall: [X.XXX]
â”œâ”€â”€ F1 Score: [X.XXX]
â”œâ”€â”€ ROC-AUC: [X.XXX]
â”œâ”€â”€ PR-AUC: [X.XXX]
â””â”€â”€ Confusion Matrix:
    â”œâ”€â”€ True Negatives: [X]
    â”œâ”€â”€ False Positives: [X]
    â”œâ”€â”€ False Negatives: [X]
    â””â”€â”€ True Positives: [X]
```

**Comparison with Baseline:**
```
Baseline (17 samples):
â”œâ”€â”€ F1: 0.857
â”œâ”€â”€ Recall: 1.000
â””â”€â”€ Precision: 0.750

Final Model ([X] samples):
â”œâ”€â”€ F1: [X.XXX] ([+/-X.XXX])
â”œâ”€â”€ Recall: [X.XXX] ([+/-X.XXX])
â””â”€â”€ Precision: [X.XXX] ([+/-X.XXX])
```

**Time Spent:** [X] hours

---

### 6. Comprehensive Evaluation (GitHub Issue #13) - [STATUS]

**Objective:** Create comprehensive evaluation pipeline and report.

**Tasks Completed:**
- [ ] Created `ml/evaluation/evaluate_model.py`
- [ ] Loaded trained model and test data
- [ ] Calculated comprehensive metrics
- [ ] Generated visualizations
- [ ] Created evaluation report
- [ ] Compared with baseline
- [ ] Documented results

**Evaluation Metrics:**
```
Classification Metrics:
â”œâ”€â”€ Accuracy: [X.XXX]
â”œâ”€â”€ Precision: [X.XXX]
â”œâ”€â”€ Recall: [X.XXX]
â”œâ”€â”€ F1 Score: [X.XXX]
â”œâ”€â”€ Specificity: [X.XXX]
â”œâ”€â”€ ROC-AUC: [X.XXX]
â””â”€â”€ PR-AUC: [X.XXX]

Per-Class Metrics:
â”œâ”€â”€ Fall (Class 1):
â”‚   â”œâ”€â”€ Precision: [X.XXX]
â”‚   â”œâ”€â”€ Recall: [X.XXX]
â”‚   â””â”€â”€ F1: [X.XXX]
â””â”€â”€ Non-Fall (Class 0):
    â”œâ”€â”€ Precision: [X.XXX]
    â”œâ”€â”€ Recall: [X.XXX]
    â””â”€â”€ F1: [X.XXX]

Error Analysis:
â”œâ”€â”€ False Positives: [X] ([X]%)
â”œâ”€â”€ False Negatives: [X] ([X]%)
â”œâ”€â”€ Fall Detection Latency: [X] frames ([X]ms)
â””â”€â”€ Per-Subject Performance: [X.XXX] Â± [X.XXX]
```

**Visualizations Generated:**
- [ ] ROC curve with AUC score
- [ ] Precision-Recall curve
- [ ] Confusion matrix heatmap
- [ ] Per-subject performance bar chart
- [ ] Detection latency histogram
- [ ] Error analysis plots

**Time Spent:** [X] hours

---

## ğŸ“Š Detailed Statistics

### Complete Pipeline
```
Raw Videos (964):
â”œâ”€â”€ Total Frames: 197,411
â””â”€â”€ Storage: ~7.6 GB

â†“ Pose Extraction (Week 2)

Keypoint Files (964):
â”œâ”€â”€ Total Frames: 197,411
â””â”€â”€ Storage: ~9 MB compressed

â†“ Feature Engineering (Week 3-4)

Feature Windows ([X]):
â”œâ”€â”€ Window Size: 60 frames
â”œâ”€â”€ Stride: 10 frames
â”œâ”€â”€ Features: 10
â””â”€â”€ Storage: [X] MB

â†“ LSTM Training (Week 4)

Final Model:
â”œâ”€â”€ Parameters: 20,289
â”œâ”€â”€ Model Size: [X] KB
â””â”€â”€ Inference Speed: [X]ms/window
```

### Code Metrics
```
Total Files Created: [X]
Total Lines of Code: [X]
â”œâ”€â”€ Source Code: [X] lines
â”œâ”€â”€ Tests: [X] lines
â””â”€â”€ Documentation: [X] lines

Test Coverage: [X]%
```

---

## ğŸš§ Challenges and Solutions

### Challenge 1: [TITLE]
**Problem:** [DESCRIPTION]
**Solution:** [DESCRIPTION]
**Impact:** [DESCRIPTION]

### Challenge 2: [TITLE]
**Problem:** [DESCRIPTION]
**Solution:** [DESCRIPTION]
**Impact:** [DESCRIPTION]

---

## ğŸ“š Learning Outcomes

1. [LEARNING 1]
2. [LEARNING 2]
3. [LEARNING 3]
4. [LEARNING 4]
5. [LEARNING 5]

---

## ğŸ“¦ Deliverables

### Code
- [ ] Updated `ml/features/feature_engineering.py` with 10 features
- [ ] Updated `ml/training/lstm_train.py` with focal loss and subject-wise splitting
- [ ] `ml/evaluation/evaluate_model.py` - Evaluation script
- [ ] `scripts/verify_split_integrity.py` - Split verification

### Models
- [ ] `ml/training/checkpoints/lstm_final.h5` - Final trained model

### Data
- [ ] `data/processed/full_windows_10feat.npz` - Full dataset with 10 features

### Documentation
- [ ] `docs/evaluation_report.md` - Comprehensive evaluation report
- [ ] Updated `docs/results1.md` with final results
- [ ] `docs/weekly_reports/WEEK_4_REPORT.md` - This report

---

## ğŸ¯ Project Completion Summary

### Overall Progress: [X]% Complete

| Phase | Status | Completion |
|-------|--------|-----------|
| Dataset Preparation | âœ… Complete | 100% |
| Pose Extraction | âœ… Complete | 100% |
| Feature Engineering | [STATUS] | [X]% |
| LSTM Training | [STATUS] | [X]% |
| Evaluation | [STATUS] | [X]% |
| Deployment | [STATUS] | [X]% |

### Target vs Actual Performance

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Precision | â‰¥ 0.90 | [X.XXX] | [âœ…/âŒ] |
| Recall | â‰¥ 0.90 | [X.XXX] | [âœ…/âŒ] |
| F1 Score | â‰¥ 0.90 | [X.XXX] | [âœ…/âŒ] |
| ROC-AUC | â‰¥ 0.90 | [X.XXX] | [âœ…/âŒ] |
| Model Size | < 500 KB | [X] KB | [âœ…/âŒ] |
| Inference Speed | < 50ms | [X]ms | [âœ…/âŒ] |

---

## â±ï¸ Time Breakdown

| Task | Planned | Actual | Notes |
|------|---------|--------|-------|
| Feature Engineering (Full) | 2-3h | [X]h | [NOTES] |
| Additional Features | 4-5h | [X]h | [NOTES] |
| Focal Loss | 2-3h | [X]h | [NOTES] |
| Subject-Wise Splitting | 3-4h | [X]h | [NOTES] |
| Final Training | 2-3h | [X]h | [NOTES] |
| Evaluation | 4-5h | [X]h | [NOTES] |
| Documentation | 2h | [X]h | [NOTES] |
| **Total** | **20-25h** | **[X]h** | **[STATUS]** |

---

## ğŸ’¡ Reflections

### What Went Well
- [ITEM 1]
- [ITEM 2]
- [ITEM 3]

### What Could Be Improved
- [ITEM 1]
- [ITEM 2]
- [ITEM 3]

### Lessons Learned
- [LESSON 1]
- [LESSON 2]
- [LESSON 3]

---

## ğŸ“ Final Project Summary

### Achievements
- [ACHIEVEMENT 1]
- [ACHIEVEMENT 2]
- [ACHIEVEMENT 3]

### Challenges Overcome
- [CHALLENGE 1]
- [CHALLENGE 2]
- [CHALLENGE 3]

### Future Work
- [FUTURE 1]
- [FUTURE 2]
- [FUTURE 3]

---

**Status:** [âœ… Complete / ğŸŸ¡ Partial / âŒ Incomplete]  
**Final Grade:** [TO BE DETERMINED]

---

*Submitted: November 15, 2025*

